{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha 전략 by 재필, feat.인수님\n",
    "\n",
    "## 필수 기재내용\n",
    "\n",
    "### 전체 프로세스 개요:\n",
    "\n",
    "- 자체제작한, 별도의 크롤링 패키지로 KRX/Naver 에서 가격, 거개량, 유동성, 시총 등의 데이터를 가져옴. \n",
    "    - 코드: https://github.com/jaepil-choi/korquanttools\n",
    "    - 각각의 데이터를 `.pickle` 로 저장해 본 코드에서 써먹음 \n",
    "- 데이터를 불러와 public 기간 전까지 자르고, 데이터를 조합하여 새로운 변수를 만듦\n",
    "    - 따라서 look-ahead 없음\n",
    "    - 새로운 변수: `close t-1`, `close t-3`, `close t-5`, `normalized rdv/adv`\n",
    "    - 각 세팅은 별도의 `submission_config.py` 모듈로 관리. (뒷부분 첨부)\n",
    "- 모델에 넣고 돌림 \n",
    "    - XGB + LGBM base model \n",
    "    - step 1, step 2, ... , step 15에 대해 따로 예측함 \n",
    "    - 시그널 만듦 \n",
    "- submission 형식에 맞게 변환\n",
    "    - `submission_util.py` 모듈로 형식에 맞게 변환함. (뒷부분 첨부)\n",
    "\n",
    "### 코드 실행환경 및 실행방법\n",
    "- 코드 실행환경\n",
    "    - python 3.9\n",
    "    - xgboost, sklearn, lightgbm, tqdm, pandas, numpy 필요\n",
    "- 실행방법\n",
    "    - .ipynb만 제출할 수 있다는 대회 제약 때문에 부득이 .py 모듈을 후반부에 첨부. 이 파일들이 있어야 코드가 돌아감. \n",
    "    - 코드를 실행하려면 drive 링크의 pickle 파일들을 받아 `/data` 폴더에 넣고, output을 넣을 `/output` 폴더도 만들어줘야 함. \n",
    "    - 그리고 노트북과 같은 폴더 안에 `submission_config.py` 와 `submission_config.py` 파일이 위치해야 함. \n",
    "\n",
    "\n",
    "나머지 과정은 아래 markdown 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom library\n",
    "\n",
    "import eda_util as eutil\n",
    "import submission_config as subconfig\n",
    "import submission_util as subutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: f'{x:,g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = subconfig.BASE_PATH\n",
    "DATA_PATH = subconfig.DATA_PATH\n",
    "\n",
    "OUTPUT_PATH = subconfig.OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "krx_df = pd.read_csv(subconfig.krx_df_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "krx_df.columns = ['date', 'code', 'name', 'volume', 'open', 'high', 'low', 'close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "krx_df['date'] = pd.to_datetime(krx_df['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df = pd.read_pickle(subconfig.return_df_PATH)\n",
    "close_df = pd.read_pickle(subconfig.adjclose_df_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_df = pd.read_pickle(subconfig.adjopen_df_PATH)\n",
    "high_df = pd.read_pickle(subconfig.adjhigh_df_PATH)\n",
    "low_df = pd.read_pickle(subconfig.adjlow_df_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## date list\n",
    "\n",
    "holidays = return_df.isnull().all(axis=1)\n",
    "tradingdays = ~holidays\n",
    "\n",
    "holidays = holidays.index[holidays]\n",
    "tradingdays = tradingdays.index[tradingdays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START = pd.to_datetime(subconfig.TRAIN_START, format='%Y-%m-%d')\n",
    "REALOS_PORTFOLIO_DATE = pd.to_datetime(subconfig.REALOS_PORTFOLIO_DATE, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradingdays = tradingdays[(tradingdays >= TRAIN_START) & (tradingdays <= REALOS_PORTFOLIO_DATE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dacon_sid_list = [ii[1:] for ii in krx_df['code'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df = return_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "return_df = return_df.loc[:, dacon_sid_list]\n",
    "\n",
    "close_df = close_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "close_df = close_df.loc[:, dacon_sid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_df = open_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "open_df = open_df.loc[:, dacon_sid_list]\n",
    "\n",
    "high_df = high_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "high_df = high_df.loc[:, dacon_sid_list]\n",
    "\n",
    "low_df = low_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "low_df = low_df.loc[:, dacon_sid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMOS_START = subconfig.SIMOS_START\n",
    "# simOS_END = subconfig.SIMOS_END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_df = pd.read_pickle(subconfig.volume_df_PATH)\n",
    "dollarvolume_df = pd.read_pickle(subconfig.dollarvolume_df_PATH)\n",
    "marketcap_df = pd.read_pickle(subconfig.marketcap_df_PATH)\n",
    "market_cat_df = pd.read_pickle(DATA_PATH / 'market_cat_df_20140101_20230730.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_df = volume_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "volume_df = volume_df.loc[:, dacon_sid_list]\n",
    "\n",
    "dollarvolume_df = dollarvolume_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "dollarvolume_df = dollarvolume_df.loc[:, dacon_sid_list]\n",
    "\n",
    "marketcap_df = marketcap_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "marketcap_df = marketcap_df.loc[:, dacon_sid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't shift data since Insoo's code already makes a shift. \n",
    "\n",
    "# volume_df = volume_df.shift(1)\n",
    "# dollarvolume_df = dollarvolume_df.shift(1)\n",
    "# marketcap_df = marketcap_df.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cat_inrange = market_cat_df[market_cat_df['trdDd'].isin(tradingdays)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "KOSPI_sid_list = market_cat_inrange[market_cat_inrange['is_KOSPI'] == True]['ISU_SRT_CD'].unique()\n",
    "KOSDAQ_sid_list = market_cat_inrange[market_cat_inrange['is_KOSDAQ'] == True]['ISU_SRT_CD'].unique()\n",
    "KONEX_sid_list = market_cat_inrange[market_cat_inrange['is_KONEX'] == True]['ISU_SRT_CD'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "REALOS_PORTFOLIO_DATE = subconfig.REALOS_PORTFOLIO_DATE\n",
    "\n",
    "RDVADV_WINDOW = subconfig.WINDOWS['rdvadv'] # 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalized RDV/ADV signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_df = dollarvolume_df.rolling(RDVADV_WINDOW, ).mean().dropna(axis='rows', how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분모: average RDV/ADV ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_adv_s = adv_df.mean(axis='columns')\n",
    "avg_rdv_s = dollarvolume_df.iloc[RDVADV_WINDOW:, :].mean(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rdvadv_s = avg_rdv_s / avg_adv_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분자: individual RDV/ADV ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_rdvadv_df = dollarvolume_df.iloc[RDVADV_WINDOW:, :] / adv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ISU_SRT_CD</th>\n",
       "      <th>060310</th>\n",
       "      <th>095570</th>\n",
       "      <th>006840</th>\n",
       "      <th>054620</th>\n",
       "      <th>265520</th>\n",
       "      <th>211270</th>\n",
       "      <th>027410</th>\n",
       "      <th>282330</th>\n",
       "      <th>126600</th>\n",
       "      <th>138930</th>\n",
       "      <th>...</th>\n",
       "      <th>243070</th>\n",
       "      <th>084110</th>\n",
       "      <th>145020</th>\n",
       "      <th>024060</th>\n",
       "      <th>010240</th>\n",
       "      <th>189980</th>\n",
       "      <th>000540</th>\n",
       "      <th>003280</th>\n",
       "      <th>037440</th>\n",
       "      <th>238490</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trdDd</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29</th>\n",
       "      <td>0.415442</td>\n",
       "      <td>0.240279</td>\n",
       "      <td>0.405709</td>\n",
       "      <td>0.726369</td>\n",
       "      <td>0.475821</td>\n",
       "      <td>0.907576</td>\n",
       "      <td>0.4201</td>\n",
       "      <td>1.10324</td>\n",
       "      <td>0.539159</td>\n",
       "      <td>0.755196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.81974</td>\n",
       "      <td>0.798739</td>\n",
       "      <td>0.631614</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>14.3229</td>\n",
       "      <td>0.996211</td>\n",
       "      <td>0.600184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.369902</td>\n",
       "      <td>0.630198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>0.314977</td>\n",
       "      <td>0.212304</td>\n",
       "      <td>0.465795</td>\n",
       "      <td>0.931287</td>\n",
       "      <td>0.470661</td>\n",
       "      <td>0.514831</td>\n",
       "      <td>0.648498</td>\n",
       "      <td>1.99712</td>\n",
       "      <td>0.354948</td>\n",
       "      <td>0.501368</td>\n",
       "      <td>...</td>\n",
       "      <td>4.39418</td>\n",
       "      <td>8.5227</td>\n",
       "      <td>0.745765</td>\n",
       "      <td>0.319291</td>\n",
       "      <td>7.08257</td>\n",
       "      <td>0.416926</td>\n",
       "      <td>1.40616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291685</td>\n",
       "      <td>0.618186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01</th>\n",
       "      <td>0.399208</td>\n",
       "      <td>0.295054</td>\n",
       "      <td>0.570299</td>\n",
       "      <td>0.366269</td>\n",
       "      <td>0.496024</td>\n",
       "      <td>0.584884</td>\n",
       "      <td>1.26369</td>\n",
       "      <td>3.66506</td>\n",
       "      <td>0.356092</td>\n",
       "      <td>0.701445</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03469</td>\n",
       "      <td>1.22015</td>\n",
       "      <td>0.426687</td>\n",
       "      <td>0.971435</td>\n",
       "      <td>1.91106</td>\n",
       "      <td>0.786424</td>\n",
       "      <td>0.705502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.495063</td>\n",
       "      <td>0.955606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-02</th>\n",
       "      <td>1.02063</td>\n",
       "      <td>0.146543</td>\n",
       "      <td>0.639072</td>\n",
       "      <td>0.410245</td>\n",
       "      <td>0.842014</td>\n",
       "      <td>0.260692</td>\n",
       "      <td>1.97162</td>\n",
       "      <td>1.5627</td>\n",
       "      <td>0.724157</td>\n",
       "      <td>0.519005</td>\n",
       "      <td>...</td>\n",
       "      <td>2.03734</td>\n",
       "      <td>0.881352</td>\n",
       "      <td>0.244086</td>\n",
       "      <td>2.64395</td>\n",
       "      <td>0.377858</td>\n",
       "      <td>0.422299</td>\n",
       "      <td>0.421016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.13061</td>\n",
       "      <td>0.666445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-24</th>\n",
       "      <td>0.288286</td>\n",
       "      <td>0.911344</td>\n",
       "      <td>1.09077</td>\n",
       "      <td>0.659324</td>\n",
       "      <td>0.56127</td>\n",
       "      <td>0.839701</td>\n",
       "      <td>0.945123</td>\n",
       "      <td>0.375129</td>\n",
       "      <td>0.659149</td>\n",
       "      <td>0.608006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808454</td>\n",
       "      <td>0.993728</td>\n",
       "      <td>0.444944</td>\n",
       "      <td>1.55736</td>\n",
       "      <td>0.426958</td>\n",
       "      <td>0.929188</td>\n",
       "      <td>0.628311</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>0.649393</td>\n",
       "      <td>0.498613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-25</th>\n",
       "      <td>0.36685</td>\n",
       "      <td>0.846063</td>\n",
       "      <td>0.898058</td>\n",
       "      <td>1.06346</td>\n",
       "      <td>0.685844</td>\n",
       "      <td>0.617804</td>\n",
       "      <td>0.719524</td>\n",
       "      <td>0.615932</td>\n",
       "      <td>0.496475</td>\n",
       "      <td>0.362459</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02346</td>\n",
       "      <td>1.02446</td>\n",
       "      <td>0.941129</td>\n",
       "      <td>1.2274</td>\n",
       "      <td>7.15383</td>\n",
       "      <td>0.858493</td>\n",
       "      <td>1.16309</td>\n",
       "      <td>0.106905</td>\n",
       "      <td>0.613637</td>\n",
       "      <td>0.343585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-26</th>\n",
       "      <td>0.255151</td>\n",
       "      <td>1.13615</td>\n",
       "      <td>0.632257</td>\n",
       "      <td>1.09468</td>\n",
       "      <td>0.862278</td>\n",
       "      <td>0.786008</td>\n",
       "      <td>0.910452</td>\n",
       "      <td>0.336899</td>\n",
       "      <td>0.533319</td>\n",
       "      <td>0.558765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929511</td>\n",
       "      <td>0.958187</td>\n",
       "      <td>0.480403</td>\n",
       "      <td>1.24321</td>\n",
       "      <td>0.582422</td>\n",
       "      <td>1.01109</td>\n",
       "      <td>0.634947</td>\n",
       "      <td>0.0964569</td>\n",
       "      <td>0.485976</td>\n",
       "      <td>0.476295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-27</th>\n",
       "      <td>0.222928</td>\n",
       "      <td>0.586442</td>\n",
       "      <td>0.412772</td>\n",
       "      <td>0.862739</td>\n",
       "      <td>0.743151</td>\n",
       "      <td>1.23313</td>\n",
       "      <td>0.98715</td>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.573359</td>\n",
       "      <td>0.957242</td>\n",
       "      <td>...</td>\n",
       "      <td>1.51065</td>\n",
       "      <td>0.420682</td>\n",
       "      <td>0.837271</td>\n",
       "      <td>0.59117</td>\n",
       "      <td>0.278487</td>\n",
       "      <td>1.01436</td>\n",
       "      <td>0.479362</td>\n",
       "      <td>0.0725815</td>\n",
       "      <td>0.386858</td>\n",
       "      <td>0.268256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-28</th>\n",
       "      <td>0.237919</td>\n",
       "      <td>0.79345</td>\n",
       "      <td>0.389487</td>\n",
       "      <td>0.885349</td>\n",
       "      <td>0.590235</td>\n",
       "      <td>1.29983</td>\n",
       "      <td>0.545772</td>\n",
       "      <td>0.422046</td>\n",
       "      <td>0.98461</td>\n",
       "      <td>0.881809</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06302</td>\n",
       "      <td>0.244384</td>\n",
       "      <td>0.559413</td>\n",
       "      <td>0.987589</td>\n",
       "      <td>0.133517</td>\n",
       "      <td>1.3962</td>\n",
       "      <td>0.177018</td>\n",
       "      <td>0.104999</td>\n",
       "      <td>0.305515</td>\n",
       "      <td>0.14872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ISU_SRT_CD   060310   095570   006840   054620   265520   211270   027410  \\\n",
       "trdDd                                                                       \n",
       "2021-06-28      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2021-06-29 0.415442 0.240279 0.405709 0.726369 0.475821 0.907576   0.4201   \n",
       "2021-06-30 0.314977 0.212304 0.465795 0.931287 0.470661 0.514831 0.648498   \n",
       "2021-07-01 0.399208 0.295054 0.570299 0.366269 0.496024 0.584884  1.26369   \n",
       "2021-07-02  1.02063 0.146543 0.639072 0.410245 0.842014 0.260692  1.97162   \n",
       "...             ...      ...      ...      ...      ...      ...      ...   \n",
       "2023-07-24 0.288286 0.911344  1.09077 0.659324  0.56127 0.839701 0.945123   \n",
       "2023-07-25  0.36685 0.846063 0.898058  1.06346 0.685844 0.617804 0.719524   \n",
       "2023-07-26 0.255151  1.13615 0.632257  1.09468 0.862278 0.786008 0.910452   \n",
       "2023-07-27 0.222928 0.586442 0.412772 0.862739 0.743151  1.23313  0.98715   \n",
       "2023-07-28 0.237919  0.79345 0.389487 0.885349 0.590235  1.29983 0.545772   \n",
       "\n",
       "ISU_SRT_CD   282330   126600   138930  ...   243070   084110   145020  \\\n",
       "trdDd                                  ...                              \n",
       "2021-06-28      NaN      NaN      NaN  ...      NaN      NaN      NaN   \n",
       "2021-06-29  1.10324 0.539159 0.755196  ...  1.81974 0.798739 0.631614   \n",
       "2021-06-30  1.99712 0.354948 0.501368  ...  4.39418   8.5227 0.745765   \n",
       "2021-07-01  3.66506 0.356092 0.701445  ...  1.03469  1.22015 0.426687   \n",
       "2021-07-02   1.5627 0.724157 0.519005  ...  2.03734 0.881352 0.244086   \n",
       "...             ...      ...      ...  ...      ...      ...      ...   \n",
       "2023-07-24 0.375129 0.659149 0.608006  ... 0.808454 0.993728 0.444944   \n",
       "2023-07-25 0.615932 0.496475 0.362459  ...  1.02346  1.02446 0.941129   \n",
       "2023-07-26 0.336899 0.533319 0.558765  ... 0.929511 0.958187 0.480403   \n",
       "2023-07-27   0.4978 0.573359 0.957242  ...  1.51065 0.420682 0.837271   \n",
       "2023-07-28 0.422046  0.98461 0.881809  ...  1.06302 0.244384 0.559413   \n",
       "\n",
       "ISU_SRT_CD   024060   010240   189980   000540    003280   037440   238490  \n",
       "trdDd                                                                       \n",
       "2021-06-28      NaN      NaN      NaN      NaN       NaN      NaN      NaN  \n",
       "2021-06-29 0.340136  14.3229 0.996211 0.600184       NaN 0.369902 0.630198  \n",
       "2021-06-30 0.319291  7.08257 0.416926  1.40616       NaN 0.291685 0.618186  \n",
       "2021-07-01 0.971435  1.91106 0.786424 0.705502       NaN 0.495063 0.955606  \n",
       "2021-07-02  2.64395 0.377858 0.422299 0.421016       NaN  1.13061 0.666445  \n",
       "...             ...      ...      ...      ...       ...      ...      ...  \n",
       "2023-07-24  1.55736 0.426958 0.929188 0.628311  0.124676 0.649393 0.498613  \n",
       "2023-07-25   1.2274  7.15383 0.858493  1.16309  0.106905 0.613637 0.343585  \n",
       "2023-07-26  1.24321 0.582422  1.01109 0.634947 0.0964569 0.485976 0.476295  \n",
       "2023-07-27  0.59117 0.278487  1.01436 0.479362 0.0725815 0.386858 0.268256  \n",
       "2023-07-28 0.987589 0.133517   1.3962 0.177018  0.104999 0.305515  0.14872  \n",
       "\n",
       "[493 rows x 2000 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_rdvadv_signal_df = ii_rdvadv_df.divide(avg_rdvadv_s, axis='rows')\n",
    "normalized_rdvadv_signal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TRAIN_START = pd.to_datetime('2021-06-29', format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating my data with Insoo's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your function to calculate SMAPE\n",
    "def smape(y_true, y_pred):\n",
    "    return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['code'] + ['return_day_' + str(i) for i in range(1, 16)])\n",
    "\n",
    "preds_df_fin_xgb = pd.DataFrame()\n",
    "smapes_df_fin_xgb = pd.DataFrame()\n",
    "\n",
    "preds_df_fin_lgbm = pd.DataFrame()\n",
    "smapes_df_fin_lgbm = pd.DataFrame()\n",
    "\n",
    "preds_df_fin_catboost = pd.DataFrame()\n",
    "smapes_df_fin_catboost = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 Ryzen 5 5600X 6 Core (CPU 12) 로 돌렸을 때 \n",
    "\n",
    "40분 가량 걸림. \n",
    "\n",
    "Windows에서 GPU 연산은 활용하기 어려움. \n",
    "\n",
    "- XGB: conda는 지원안함, Windows는 version conflict 남\n",
    "- LGBM: Linux만 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each unique stock\n",
    "for code in tqdm(dacon_sid_list):\n",
    "    \n",
    "    # Filter by stock code\n",
    "    # Note: All prices are adjusted\n",
    "    # TODO: Add normalized rdvadv signal to the columns\n",
    "\n",
    "    train_close = pd.DataFrame(\n",
    "        data={\n",
    "            'open': open_df.loc[MODEL_TRAIN_START:REALOS_PORTFOLIO_DATE, code],\n",
    "            'high': high_df.loc[MODEL_TRAIN_START:REALOS_PORTFOLIO_DATE, code],\n",
    "            'low': low_df.loc[MODEL_TRAIN_START:REALOS_PORTFOLIO_DATE, code],\n",
    "            'close': close_df.loc[MODEL_TRAIN_START:REALOS_PORTFOLIO_DATE, code],\n",
    "            'close_t-1': close_df.loc[MODEL_TRAIN_START:REALOS_PORTFOLIO_DATE, code].shift(1),\n",
    "            'close_t-3': close_df.loc[MODEL_TRAIN_START:REALOS_PORTFOLIO_DATE, code].shift(3),\n",
    "            'close_t-5': close_df.loc[MODEL_TRAIN_START:REALOS_PORTFOLIO_DATE, code].shift(5),\n",
    "            'dollarvolume': dollarvolume_df.loc[MODEL_TRAIN_START:REALOS_PORTFOLIO_DATE, code],\n",
    "            'marketcap': marketcap_df.loc[MODEL_TRAIN_START:REALOS_PORTFOLIO_DATE, code],\n",
    "            'norm_rdvadv': normalized_rdvadv_signal_df.loc[MODEL_TRAIN_START:REALOS_PORTFOLIO_DATE, code],\n",
    "        }\n",
    "        )\n",
    "    train_close = train_close.iloc[5:, :] # nan 있는 1st row 제거 \n",
    "\n",
    "    # Store original data for reference\n",
    "    original_data = train_close.copy()\n",
    "\n",
    "    # Create return columns for each day\n",
    "    returns = []\n",
    "    smapes_xgb = []\n",
    "    smapes_lgbm = []\n",
    "    smapes_catboost = []\n",
    "\n",
    "    preds_df_xgb = pd.DataFrame()\n",
    "    preds_df_lgbm = pd.DataFrame()\n",
    "    preds_df_catboost = pd.DataFrame()\n",
    "    \n",
    "    # For each day from 1 to 15\n",
    "    for day in range(1, 16):\n",
    "        # Scale data\n",
    "        X = train_close[:]\n",
    "        y = train_close['close']\n",
    "        \n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        data_scaled = scaler.fit_transform(X)\n",
    "        data_scaled2 = y\n",
    "        \n",
    "        X_train = data_scaled[:-day]\n",
    "        y_train = data_scaled2[day:]\n",
    "        X_test = data_scaled[-day]\n",
    "        \n",
    "        X_train = X_train[:int(len(X_train) * 0.9)]\n",
    "        X_val = X_train[int(len(X_train) * 0.9):]\n",
    "        y_train = y_train[:int(len(y_train) * 0.9)]\n",
    "        y_val = y_train[int(len(y_train) * 0.9):] \n",
    "\n",
    "        # Train XGBoost\n",
    "        xgb_model = XGBRegressor()\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        vals_xgb = xgb_model.predict(X_val)\n",
    "        smapes_xgb.append(smape(y_val, vals_xgb))\n",
    "        \n",
    "        preds_xgb = xgb_model.predict([data_scaled[-day]])\n",
    "        preds_df_xgb = pd.concat([preds_df_xgb, pd.DataFrame(preds_xgb)], axis = 0)\n",
    "\n",
    "        # Train LightGBM\n",
    "        lgbm_model = LGBMRegressor()\n",
    "        lgbm_model.fit(X_train, y_train)\n",
    "        vals_lgbm = lgbm_model.predict(X_val)\n",
    "        smapes_lgbm.append(smape(y_val, vals_lgbm))\n",
    "        \n",
    "        preds_lgbm = lgbm_model.predict([data_scaled[-day]])\n",
    "        preds_df_lgbm = pd.concat([preds_df_lgbm, pd.DataFrame(preds_lgbm)], axis = 0)\n",
    "    \n",
    "    smapes_df_xgb = pd.DataFrame(smapes_xgb)\n",
    "    smapes_df_lgbm = pd.DataFrame(smapes_lgbm)\n",
    "    smapes_df_catboost = pd.DataFrame(smapes_catboost)\n",
    "\n",
    "    preds_df_fin_xgb = pd.concat([preds_df_fin_xgb, preds_df_xgb], axis = 1)\n",
    "    smapes_df_fin_xgb = pd.concat([smapes_df_fin_xgb, smapes_df_xgb], axis = 1)\n",
    "\n",
    "    preds_df_fin_lgbm = pd.concat([preds_df_fin_lgbm, preds_df_lgbm], axis = 1)\n",
    "    smapes_df_fin_lgbm = pd.concat([smapes_df_fin_lgbm, smapes_df_lgbm], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smapes_df_xgb.to_pickle(OUTPUT_PATH / 'smapes_df_xgb.pickle')\n",
    "# smapes_df_lgbm.to_pickle(OUTPUT_PATH / 'smapes_df_lgbm.pickle')\n",
    "# smapes_df_catboost.to_pickle(OUTPUT_PATH / 'smapes_df_catboost.pickle')\n",
    "\n",
    "# preds_df_fin_xgb.to_pickle(OUTPUT_PATH / 'preds_df_fin_xgb.pickle')\n",
    "# smapes_df_fin_xgb.to_pickle(OUTPUT_PATH / 'smapes_df_fin_xgb.pickle')\n",
    "\n",
    "# preds_df_fin_lgbm.to_pickle(OUTPUT_PATH / 'preds_df_fin_lgbm.pickle')\n",
    "# smapes_df_fin_lgbm.to_pickle(OUTPUT_PATH / 'smapes_df_fin_lgbm.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 2000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smapes_df_fin_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 2000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smapes_df_fin_lgbm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_59232\\3629398345.py:7: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  1 / smapes_df_fin_lgbm.iloc[j:j+1, i].values[0]]\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_59232\\3629398345.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  weights /= np.sum(weights)\n",
      "C:\\Users\\chlje\\AppData\\Local\\Temp\\ipykernel_59232\\3629398345.py:5: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  weights = [1 / smapes_df_fin_xgb.iloc[j:j+1, i].values[0],\n"
     ]
    }
   ],
   "source": [
    "final = np.zeros((len(smapes_df_fin_xgb), len(smapes_df_fin_xgb.columns)))\n",
    "\n",
    "for i in range(0, len(smapes_df_fin_xgb.columns)):\n",
    "    for j in range(0, len(smapes_df_fin_xgb)):\n",
    "        weights = [1 / smapes_df_fin_xgb.iloc[j:j+1, i].values[0],\n",
    "                   \n",
    "                   1 / smapes_df_fin_lgbm.iloc[j:j+1, i].values[0]]\n",
    "        \n",
    "\n",
    "        weights /= np.sum(weights) \n",
    "        \n",
    "\n",
    "        final[j][i] = weights[0] * preds_df_fin_xgb.iloc[j:j+1, i].values[0] \\\n",
    "                            + weights[1] * preds_df_fin_lgbm.iloc[j:j+1, i].values[0] \\\n",
    "                        #     + weights[2] * preds_df_fin_lgbm.iloc[j:j+1, i].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final)\n",
    "final_values = pd.DataFrame((final_df.iloc[-1] - final_df.iloc[0]) / final_df.iloc[0])\n",
    "final_values_sharpe = -pd.DataFrame(((final_df.iloc[-1] - final_df.iloc[0]) / final_df.iloc[0]) / final_df.pct_change().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_values_sharpe.index = dacon_sid_list\n",
    "final_values_sharpe.columns = ['VALUE']\n",
    "final_values_sharpe.reset_index(inplace = True)\n",
    "final_values_sharpe.columns = ['종목코드', 'VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_values_sharpe.set_index('종목코드', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "종목코드\n",
       "060310   -2.78023\n",
       "095570   -2.69839\n",
       "006840    1.87109\n",
       "054620   -4.28813\n",
       "265520   -1.83038\n",
       "           ...   \n",
       "189980    -1.7422\n",
       "000540    1.72483\n",
       "003280   -8.68666\n",
       "037440   -1.73952\n",
       "238490   0.735532\n",
       "Name: VALUE, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_values_sharpe['VALUE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_feat_insoo = subutil.Submission(\n",
    "    alpha_series=final_values_sharpe['VALUE'],\n",
    "    alpha_name='alpha_feat_insoo_lagged_ReverseSharpe-final',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to E:\\VSCodeProjects\\daconKRX2023\\output\\alpha_feat_insoo_lagged_ReverseSharpe-final.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>순위</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>종목코드</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A060310</th>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A095570</th>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A006840</th>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A054620</th>\n",
       "      <td>1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A265520</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A189980</th>\n",
       "      <td>1797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A000540</th>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A003280</th>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A037440</th>\n",
       "      <td>1799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A238490</th>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           순위\n",
       "종목코드         \n",
       "A060310   201\n",
       "A095570   202\n",
       "A006840   203\n",
       "A054620  1824\n",
       "A265520   204\n",
       "...       ...\n",
       "A189980  1797\n",
       "A000540  1798\n",
       "A003280  1992\n",
       "A037440  1799\n",
       "A238490  1800\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_feat_insoo.get_rank(export_path=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함께 사용된 Python 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`submission_config.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "## Path configs\n",
    "\n",
    "BASE_PATH = Path('.').resolve()\n",
    "DATA_PATH = BASE_PATH / 'data'\n",
    "OUTPUT_PATH = BASE_PATH / 'output'\n",
    "\n",
    "krx_df_PATH = DATA_PATH / 'train.csv'\n",
    "return_df_PATH = DATA_PATH / 'return_20140101_20230730.pkl'\n",
    "adjclose_df_PATH = DATA_PATH / 'adjClose_20140101_20230730.pkl'\n",
    "adjhigh_df_PATH = DATA_PATH / 'adjHigh_20140101_20230730.pkl'\n",
    "adjlow_df_PATH = DATA_PATH / 'adjLow_20140101_20230730.pkl'\n",
    "adjopen_df_PATH = DATA_PATH / 'adjOpen_20140101_20230730.pkl'\n",
    "volume_df_PATH = DATA_PATH / 'volume_df_20140101_20230730.pkl'\n",
    "dollarvolume_df_PATH = DATA_PATH / 'dollarvolume_df_20140101_20230730.pkl'\n",
    "marketcap_df_PATH = DATA_PATH / 'marketcap_df_20140101_20230730.pkl'\n",
    "\n",
    "## Param configs\n",
    "\n",
    "# train (custom)\n",
    "TRAIN_START = '2021-06-01'\n",
    "\n",
    "# SimOS\n",
    "PORTFOLIO_DATE = '2023-05-30' \n",
    "SIMOS_START = '2023-05-31'\n",
    "SIMOS_END = '2023-06-21'\n",
    "\n",
    "# RealOS\n",
    "REALOS_PORTFOLIO_DATE = '2023-07-28' \n",
    "REALOS_START = '2023-07-31'\n",
    "\n",
    "WINDOWS = {\n",
    "    'rdvadv': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`submission_util.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    roc_auc_score, \n",
    "    roc_curve, \n",
    "    auc\n",
    "    )\n",
    "# TODO: SimOS 에서의 정답을 알고있다. 그러므로 eval metric 계산할 수 있다. \n",
    "\n",
    "import submission_config as subconfig\n",
    "\n",
    "## Params\n",
    "DACON_SID_CNT = 2000\n",
    "SIMOS_START = subconfig.SIMOS_START\n",
    "SIMOS_END = subconfig.SIMOS_END\n",
    "\n",
    "## Import data\n",
    "krx_df = pd.read_csv(subconfig.krx_df_PATH)\n",
    "adjclose_df = pd.read_pickle(subconfig.adjclose_df_PATH)\n",
    "return_df = pd.read_pickle(subconfig.return_df_PATH)\n",
    "\n",
    "def get_simos_data(return_df, adjclose_df):\n",
    "    holidays = return_df.isnull().all(axis=1)\n",
    "    tradingdays = ~holidays\n",
    "\n",
    "    holidays = holidays.index[holidays]\n",
    "    tradingdays = tradingdays.index[tradingdays]\n",
    "\n",
    "    return_df = return_df.loc[tradingdays, :]\n",
    "    adjclose_df = adjclose_df.loc[tradingdays, :]\n",
    "\n",
    "    return_df = return_df.loc[SIMOS_START:SIMOS_END, :]\n",
    "    adjclose_df = adjclose_df.loc[SIMOS_START:SIMOS_END, :]\n",
    "\n",
    "    return return_df, adjclose_df\n",
    "\n",
    "# TODO: Confusing if global variables are not capitalized\n",
    "simos_return_df, simos_adjclose_df = get_simos_data(return_df, adjclose_df) # simos period, only trading days\n",
    "\n",
    "## for filtering\n",
    "def get_tradables(adjclose_df, trading_date=subconfig.PORTFOLIO_DATE):\n",
    "    sid_list = adjclose_df.columns\n",
    "\n",
    "    notnull = adjclose_df.loc[trading_date, :].notnull()\n",
    "    notzero = adjclose_df.loc[trading_date, :] != 0\n",
    "\n",
    "    return sid_list[notnull * notzero]\n",
    "\n",
    "def is_tradables(sid_list, tradables):\n",
    "    tradables = set(tradables)\n",
    "\n",
    "    return np.array([True if sid in tradables else False for sid in sid_list])\n",
    "\n",
    "def get_daconsids(krx_df):\n",
    "    krx_df.columns = ['date', 'code', 'name', 'volume', 'open', 'high', 'low', 'close']\n",
    "    dacon_sid_list = [ii[1:] for ii in krx_df['code'].unique()] # 060310 형식으로 바꿔줌\n",
    "\n",
    "    return dacon_sid_list\n",
    "\n",
    "def is_daconsids(sid_list, daconsids):\n",
    "    daconsids = set(daconsids)\n",
    "\n",
    "    return np.array([True if sid in daconsids else False for sid in sid_list])\n",
    "\n",
    "class Submission:\n",
    "    holding_return_s = (simos_adjclose_df.loc[SIMOS_END, :] - simos_adjclose_df.loc[SIMOS_START, :]).divide(simos_adjclose_df.loc[SIMOS_START, :])  \n",
    "    holding_return_s = holding_return_s.fillna(0)\n",
    "\n",
    "    # simos_winners = \n",
    "    # TODO: Add data science evaluation metrics\n",
    "\n",
    "    # TODO: Make not-instance-specific variables to class variables\n",
    "    def __init__(self, alpha_series:pd.Series, alpha_name:str, top=200, bottom=200):\n",
    "        self.alpha_series = alpha_series\n",
    "        self.alpha_name = alpha_name\n",
    "        self.top = top\n",
    "        self.bottom = bottom\n",
    "\n",
    "        self.sid_list = self.alpha_series.index\n",
    "        self.tradables = get_tradables(adjclose_df)\n",
    "        self.daconsids = get_daconsids(krx_df)\n",
    "    \n",
    "        self.is_selectables = is_tradables(self.sid_list, self.tradables) * is_daconsids(self.sid_list, self.daconsids)\n",
    "        self.submission_df = None\n",
    "        self.alpha_winners = None\n",
    "        self.alpha_losers = None\n",
    "\n",
    "        # for excess return\n",
    "        self.long_hpr = None\n",
    "        self.short_hpr = None\n",
    "        self.final_return = None\n",
    "\n",
    "        # for variance\n",
    "        self.long_returns = None\n",
    "        self.short_returns = None\n",
    "        \n",
    "    def get_rank(self, export_path=None):\n",
    "        selectables = self.alpha_series[self.is_selectables]\n",
    "        top_s = selectables.nlargest(self.top)\n",
    "        bottom_s = selectables.nsmallest(self.bottom)\n",
    "        \n",
    "        self.alpha_winners = top_s.index\n",
    "        self.alpha_losers = bottom_s.index\n",
    "        \n",
    "        submission_df = pd.DataFrame(\n",
    "            data={'rank': [-1]*DACON_SID_CNT},\n",
    "            index=self.daconsids\n",
    "        )\n",
    "        submission_df.index.name = 'sid'\n",
    "\n",
    "        submission_df['rank'][top_s.index] = np.arange(1, self.top+1)\n",
    "        submission_df['rank'][bottom_s.index] = np.arange(DACON_SID_CNT, DACON_SID_CNT - self.bottom, -1)\n",
    "\n",
    "        submission_df['rank'][submission_df['rank'] == -1] = np.arange(self.top+1, DACON_SID_CNT - self.bottom + 1)\n",
    "\n",
    "        self.submission_df = submission_df\n",
    "\n",
    "        if export_path:\n",
    "            submission_df.index = ['A' + idx for idx in submission_df.index]\n",
    "            submission_df.index.name = '종목코드'\n",
    "            submission_df.columns = ['순위']\n",
    "            submission_df.to_csv(export_path / f'{self.alpha_name}.csv', encoding='utf-8')\n",
    "            \n",
    "            print(f'Saved to {export_path / self.alpha_name}.csv')\n",
    "            return submission_df\n",
    "\n",
    "        return submission_df\n",
    "\n",
    "    def get_excess_return(self, risk_free_rate=0.035, days_of_trading=15):\n",
    "        self.long_hpr = Submission.holding_return_s[self.alpha_winners].sum()\n",
    "        self.short_hpr = Submission.holding_return_s[self.alpha_losers].sum()\n",
    "\n",
    "        self.final_return = (self.long_hpr - self.short_hpr) / 400\n",
    "\n",
    "        annualized_final_return = self.final_return * 250 / days_of_trading\n",
    "        excess_return = annualized_final_return - risk_free_rate\n",
    "\n",
    "        return excess_return\n",
    "    \n",
    "    def get_volatility(self, days_of_trading=15):\n",
    "        self.long_returns = simos_return_df.loc[:, self.alpha_winners].mean(axis=1)\n",
    "        self.short_returns = simos_return_df.loc[:, self.alpha_losers].mean(axis=1)\n",
    "\n",
    "        annualized_portfolio_returns = (self.long_returns - self.short_returns) / 2 * 250\n",
    "        annualized_mean_returns = annualized_portfolio_returns.mean()\n",
    "        \n",
    "        annualized_portfolio_volatility = np.sqrt((annualized_portfolio_returns - annualized_mean_returns).pow(2)[2:].sum() / (days_of_trading-2))\n",
    "\n",
    "        return annualized_portfolio_volatility\n",
    "\n",
    "    def get_Sharpe(self):\n",
    "        return self.get_excess_return() / self.get_volatility()\n",
    "\n",
    "    \n",
    "class Score:\n",
    "    holding_return_s = (simos_adjclose_df.loc[SIMOS_END, :] - simos_adjclose_df.loc[SIMOS_START, :]).divide(simos_adjclose_df.loc[SIMOS_START, :])  \n",
    "    holding_return_s = holding_return_s.fillna(0)\n",
    "\n",
    "    def __init__(self, submission_csv_filepath, alpha_name, top=200, bottom=200, encoding='utf-8'):\n",
    "        self.alpha_name = alpha_name\n",
    "        self.top = top\n",
    "        self.bottom = bottom\n",
    "\n",
    "        with open(submission_csv_filepath, 'r', encoding=encoding) as f:\n",
    "            submission_df = pd.read_csv(f, index_col=0)\n",
    "        \n",
    "        submission_df.index = [idx[1:] for idx in submission_df.index]\n",
    "        submission_df.index.name = 'sid'\n",
    "        submission_df.columns = ['rank']\n",
    "\n",
    "        self.alpha_series = submission_df['rank']\n",
    "        self.sid_list = self.alpha_series.index\n",
    "\n",
    "        # TODO: Add validations\n",
    "\n",
    "        self.submission_df = None\n",
    "        self.alpha_winners = self.alpha_series.nsmallest(self.top).index\n",
    "        self.alpha_losers = self.alpha_series.nlargest(self.bottom).index\n",
    "\n",
    "        # for excess return\n",
    "        self.long_hpr = None\n",
    "        self.short_hpr = None\n",
    "        self.final_return = None\n",
    "\n",
    "        # for variance\n",
    "        self.long_returns = None\n",
    "        self.short_returns = None\n",
    "    \n",
    "    def get_excess_return(self, risk_free_rate=0.035, days_of_trading=15):\n",
    "        self.long_hpr = Score.holding_return_s[self.alpha_winners].sum()\n",
    "        self.short_hpr = Score.holding_return_s[self.alpha_losers].sum()\n",
    "\n",
    "        self.final_return = (self.long_hpr - self.short_hpr) / 400\n",
    "\n",
    "        annualized_final_return = self.final_return * 250 / days_of_trading\n",
    "        excess_return = annualized_final_return - risk_free_rate\n",
    "\n",
    "        return excess_return\n",
    "\n",
    "    def get_volatility(self, days_of_trading=15):\n",
    "        self.long_returns = simos_return_df.loc[:, self.alpha_winners].mean(axis=1)\n",
    "        self.short_returns = simos_return_df.loc[:, self.alpha_losers].mean(axis=1)\n",
    "\n",
    "        annualized_portfolio_returns = (self.long_returns - self.short_returns) / 2 * 250\n",
    "        annualized_mean_returns = annualized_portfolio_returns.mean()\n",
    "        \n",
    "        annualized_portfolio_volatility = np.sqrt((annualized_portfolio_returns - annualized_mean_returns).pow(2)[2:].sum() / (days_of_trading-2))\n",
    "\n",
    "        return annualized_portfolio_volatility\n",
    "\n",
    "    def get_Sharpe(self):\n",
    "        sharpe = self.get_excess_return() / self.get_volatility()\n",
    "        print(f'Sharpe of {self.alpha_name}: {sharpe}')\n",
    "\n",
    "        return sharpe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
