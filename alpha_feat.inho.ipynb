{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha 전략 feat.인호님\n",
    "\n",
    "기존 데이터에 인호님 코드 합쳐 돌려보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom library\n",
    "\n",
    "import eda_util as eutil\n",
    "import submission_config as subconfig\n",
    "import submission_util as subutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: f'{x:,g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = subconfig.BASE_PATH\n",
    "DATA_PATH = subconfig.DATA_PATH\n",
    "\n",
    "OUTPUT_PATH = subconfig.OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "krx_df = pd.read_csv(subconfig.krx_df_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "krx_df.columns = ['date', 'code', 'name', 'volume', 'open', 'high', 'low', 'close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "krx_df['date'] = pd.to_datetime(krx_df['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df = pd.read_pickle(subconfig.return_df_PATH)\n",
    "close_df = pd.read_pickle(subconfig.adjclose_df_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_df = pd.read_pickle(subconfig.adjopen_df_PATH)\n",
    "high_df = pd.read_pickle(subconfig.adjhigh_df_PATH)\n",
    "low_df = pd.read_pickle(subconfig.adjlow_df_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## date list\n",
    "\n",
    "holidays = return_df.isnull().all(axis=1)\n",
    "tradingdays = ~holidays\n",
    "\n",
    "holidays = holidays.index[holidays]\n",
    "tradingdays = tradingdays.index[tradingdays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START = pd.to_datetime(subconfig.TRAIN_START, format='%Y-%m-%d')\n",
    "SIMOS_END = pd.to_datetime(subconfig.SIMOS_END, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradingdays = tradingdays[(tradingdays >= TRAIN_START) & (tradingdays <= SIMOS_END)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dacon_sid_list = [ii[1:] for ii in krx_df['code'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df = return_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "return_df = return_df.loc[:, dacon_sid_list]\n",
    "\n",
    "close_df = close_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "close_df = close_df.loc[:, dacon_sid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_df = open_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "open_df = open_df.loc[:, dacon_sid_list]\n",
    "\n",
    "high_df = high_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "high_df = high_df.loc[:, dacon_sid_list]\n",
    "\n",
    "low_df = low_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "low_df = low_df.loc[:, dacon_sid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMOS_START = subconfig.SIMOS_START\n",
    "# simOS_END = subconfig.SIMOS_END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_df = pd.read_pickle(subconfig.volume_df_PATH)\n",
    "dollarvolume_df = pd.read_pickle(subconfig.dollarvolume_df_PATH)\n",
    "marketcap_df = pd.read_pickle(subconfig.marketcap_df_PATH)\n",
    "market_cat_df = pd.read_pickle(DATA_PATH / 'market_cat_df_20140101_20230705.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_df = volume_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "volume_df = volume_df.loc[:, dacon_sid_list]\n",
    "\n",
    "dollarvolume_df = dollarvolume_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "dollarvolume_df = dollarvolume_df.loc[:, dacon_sid_list]\n",
    "\n",
    "marketcap_df = marketcap_df.loc[tradingdays, :].dropna(axis='columns', how='all')\n",
    "marketcap_df = marketcap_df.loc[:, dacon_sid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_df = volume_df.shift(1)\n",
    "dollarvolume_df = dollarvolume_df.shift(1)\n",
    "marketcap_df = marketcap_df.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cat_inrange = market_cat_df[market_cat_df['trdDd'].isin(tradingdays)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "KOSPI_sid_list = market_cat_inrange[market_cat_inrange['is_KOSPI'] == True]['ISU_SRT_CD'].unique()\n",
    "KOSDAQ_sid_list = market_cat_inrange[market_cat_inrange['is_KOSDAQ'] == True]['ISU_SRT_CD'].unique()\n",
    "KONEX_sid_list = market_cat_inrange[market_cat_inrange['is_KONEX'] == True]['ISU_SRT_CD'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "PORTFOLIO_DATE = subconfig.PORTFOLIO_DATE\n",
    "\n",
    "RDVADV_WINDOW = subconfig.WINDOWS['rdvadv'] # 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating my data with Inho's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your function to calculate SMAPE\n",
    "def smape(y_true, y_pred):\n",
    "    return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['code'] + ['return_day_' + str(i) for i in range(1, 16)])\n",
    "\n",
    "preds_df_fin_xgb = pd.DataFrame()\n",
    "smapes_df_fin_xgb = pd.DataFrame()\n",
    "\n",
    "preds_df_fin_lgbm = pd.DataFrame()\n",
    "smapes_df_fin_lgbm = pd.DataFrame()\n",
    "\n",
    "preds_df_fin_catboost = pd.DataFrame()\n",
    "smapes_df_fin_catboost = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '005930'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_close = pd.DataFrame(\n",
    "    data={\n",
    "        'open': open_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "        'high': high_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "        'low': low_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "        'close': close_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "        'dollarvolume': dollarvolume_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "        'marketcap': marketcap_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "    }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>dollarvolume</th>\n",
       "      <th>marketcap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trdDd</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-01</th>\n",
       "      <td>80,500</td>\n",
       "      <td>81,300</td>\n",
       "      <td>80,100</td>\n",
       "      <td>80,600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>80,400</td>\n",
       "      <td>81,400</td>\n",
       "      <td>80,300</td>\n",
       "      <td>80,800</td>\n",
       "      <td>1.13546e+12</td>\n",
       "      <td>4.81164e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>81,300</td>\n",
       "      <td>83,000</td>\n",
       "      <td>81,100</td>\n",
       "      <td>82,800</td>\n",
       "      <td>1.32771e+12</td>\n",
       "      <td>4.82358e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-04</th>\n",
       "      <td>82,700</td>\n",
       "      <td>82,700</td>\n",
       "      <td>81,500</td>\n",
       "      <td>82,200</td>\n",
       "      <td>2.43812e+12</td>\n",
       "      <td>4.94298e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-07</th>\n",
       "      <td>82,700</td>\n",
       "      <td>82,800</td>\n",
       "      <td>81,600</td>\n",
       "      <td>81,900</td>\n",
       "      <td>1.48779e+12</td>\n",
       "      <td>4.90716e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-24</th>\n",
       "      <td>68,100</td>\n",
       "      <td>68,700</td>\n",
       "      <td>68,000</td>\n",
       "      <td>68,500</td>\n",
       "      <td>5.85923e+11</td>\n",
       "      <td>4.08333e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-25</th>\n",
       "      <td>69,900</td>\n",
       "      <td>70,000</td>\n",
       "      <td>68,700</td>\n",
       "      <td>68,800</td>\n",
       "      <td>5.60469e+11</td>\n",
       "      <td>4.0893e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-26</th>\n",
       "      <td>69,800</td>\n",
       "      <td>70,400</td>\n",
       "      <td>69,500</td>\n",
       "      <td>70,300</td>\n",
       "      <td>9.84569e+11</td>\n",
       "      <td>4.10721e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-30</th>\n",
       "      <td>71,300</td>\n",
       "      <td>72,300</td>\n",
       "      <td>71,200</td>\n",
       "      <td>72,300</td>\n",
       "      <td>1.37067e+12</td>\n",
       "      <td>4.19676e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-31</th>\n",
       "      <td>72,400</td>\n",
       "      <td>72,500</td>\n",
       "      <td>71,000</td>\n",
       "      <td>71,400</td>\n",
       "      <td>1.97502e+12</td>\n",
       "      <td>4.31615e+14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>471 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             open   high    low  close  dollarvolume   marketcap\n",
       "trdDd                                                           \n",
       "2021-06-01 80,500 81,300 80,100 80,600           NaN         NaN\n",
       "2021-06-02 80,400 81,400 80,300 80,800   1.13546e+12 4.81164e+14\n",
       "2021-06-03 81,300 83,000 81,100 82,800   1.32771e+12 4.82358e+14\n",
       "2021-06-04 82,700 82,700 81,500 82,200   2.43812e+12 4.94298e+14\n",
       "2021-06-07 82,700 82,800 81,600 81,900   1.48779e+12 4.90716e+14\n",
       "...           ...    ...    ...    ...           ...         ...\n",
       "2023-05-24 68,100 68,700 68,000 68,500   5.85923e+11 4.08333e+14\n",
       "2023-05-25 69,900 70,000 68,700 68,800   5.60469e+11  4.0893e+14\n",
       "2023-05-26 69,800 70,400 69,500 70,300   9.84569e+11 4.10721e+14\n",
       "2023-05-30 71,300 72,300 71,200 72,300   1.37067e+12 4.19676e+14\n",
       "2023-05-31 72,400 72,500 71,000 71,400   1.97502e+12 4.31615e+14\n",
       "\n",
       "[471 rows x 6 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [42:10<00:00,  1.27s/it] \n"
     ]
    }
   ],
   "source": [
    "# Iterate over each unique stock\n",
    "for code in tqdm(dacon_sid_list):\n",
    "    \n",
    "    # Filter by stock code\n",
    "    # Note: All prices are adjusted\n",
    "    # TODO: Add normalized rdvadv signal to the columns\n",
    "\n",
    "    train_close = pd.DataFrame(\n",
    "        data={\n",
    "            'open': open_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "            'high': high_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "            'low': low_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "            'close': close_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "            'dollarvolume': dollarvolume_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "            'marketcap': marketcap_df.loc[TRAIN_START:SIMOS_START, code],\n",
    "        }\n",
    "        )\n",
    "    train_close = train_close.iloc[1:, :]\n",
    "\n",
    "    # Store original data for reference\n",
    "    original_data = train_close.copy()\n",
    "\n",
    "    # Create return columns for each day\n",
    "    returns = []\n",
    "    smapes_xgb = []\n",
    "    smapes_lgbm = []\n",
    "    smapes_catboost = []\n",
    "\n",
    "    preds_df_xgb = pd.DataFrame()\n",
    "    preds_df_lgbm = pd.DataFrame()\n",
    "    preds_df_catboost = pd.DataFrame()\n",
    "    \n",
    "    # For each day from 1 to 15\n",
    "    for day in range(1, 16):\n",
    "        # Scale data\n",
    "        X = train_close[:]\n",
    "        y = train_close['close']\n",
    "        \n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        data_scaled = scaler.fit_transform(X)\n",
    "        data_scaled2 = y\n",
    "        \n",
    "        X_train = data_scaled[:-day]\n",
    "        y_train = data_scaled2[day:]\n",
    "        X_test = data_scaled[-day]\n",
    "        \n",
    "        X_train = X_train[:int(len(X_train) * 0.9)]\n",
    "        X_val = X_train[int(len(X_train) * 0.9):]\n",
    "        y_train = y_train[:int(len(y_train) * 0.9)]\n",
    "        y_val = y_train[int(len(y_train) * 0.9):] \n",
    "\n",
    "        # Train XGBoost\n",
    "        xgb_model = XGBRegressor()\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        vals_xgb = xgb_model.predict(X_val)\n",
    "        smapes_xgb.append(smape(y_val, vals_xgb))\n",
    "        \n",
    "        preds_xgb = xgb_model.predict([data_scaled[-day]])\n",
    "        preds_df_xgb = pd.concat([preds_df_xgb, pd.DataFrame(preds_xgb)], axis = 0)\n",
    "\n",
    "        # Train LightGBM\n",
    "        lgbm_model = LGBMRegressor()\n",
    "        lgbm_model.fit(X_train, y_train)\n",
    "        vals_lgbm = lgbm_model.predict(X_val)\n",
    "        smapes_lgbm.append(smape(y_val, vals_lgbm))\n",
    "        \n",
    "        preds_lgbm = lgbm_model.predict([data_scaled[-day]])\n",
    "        preds_df_lgbm = pd.concat([preds_df_lgbm, pd.DataFrame(preds_lgbm)], axis = 0)\n",
    "    \n",
    "    smapes_df_xgb = pd.DataFrame(smapes_xgb)\n",
    "    smapes_df_lgbm = pd.DataFrame(smapes_lgbm)\n",
    "    smapes_df_catboost = pd.DataFrame(smapes_catboost)\n",
    "\n",
    "    preds_df_fin_xgb = pd.concat([preds_df_fin_xgb, preds_df_xgb], axis = 1)\n",
    "    smapes_df_fin_xgb = pd.concat([smapes_df_fin_xgb, smapes_df_xgb], axis = 1)\n",
    "\n",
    "    preds_df_fin_lgbm = pd.concat([preds_df_fin_lgbm, preds_df_lgbm], axis = 1)\n",
    "    smapes_df_fin_lgbm = pd.concat([smapes_df_fin_lgbm, smapes_df_lgbm], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smapes_df_xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m smapes_df_xgb\u001b[39m.\u001b[39mto_pickle(OUTPUT_PATH \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39msmapes_df_xgb.pickle\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'smapes_df_xgb' is not defined"
     ]
    }
   ],
   "source": [
    "smapes_df_xgb.to_pickle(OUTPUT_PATH / 'smapes_df_xgb.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 13\u001b[0m\n\u001b[0;32m      5\u001b[0m weights \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m smapes_df_fin_xgb\u001b[39m.\u001b[39miloc[j:j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, i]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m],\n\u001b[0;32m      6\u001b[0m            \n\u001b[0;32m      7\u001b[0m            \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m smapes_df_fin_lgbm\u001b[39m.\u001b[39miloc[j:j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, i]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]]\n\u001b[0;32m     10\u001b[0m weights \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(weights) \n\u001b[0;32m     11\u001b[0m final[j][i] \u001b[39m=\u001b[39m weights[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m preds_df_fin_xgb\u001b[39m.\u001b[39miloc[j:j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, i]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m] \\\n\u001b[0;32m     12\u001b[0m                     \u001b[39m+\u001b[39m weights[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m preds_df_fin_lgbm\u001b[39m.\u001b[39miloc[j:j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, i]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m] \\\n\u001b[1;32m---> 13\u001b[0m                     \u001b[39m+\u001b[39m weights[\u001b[39m2\u001b[39;49m] \u001b[39m*\u001b[39m preds_df_fin_lgbm\u001b[39m.\u001b[39miloc[j:j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, i]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "final = np.zeros((len(smapes_df_fin_xgb), len(smapes_df_fin_xgb.columns)))\n",
    "\n",
    "for i in range(0, len(smapes_df_fin_xgb.columns)):\n",
    "    for j in range(0, len(smapes_df_fin_xgb)):\n",
    "        weights = [1 / smapes_df_fin_xgb.iloc[j:j+1, i].values[0],\n",
    "                   \n",
    "                   1 / smapes_df_fin_lgbm.iloc[j:j+1, i].values[0]]\n",
    "        \n",
    "\n",
    "        weights /= np.sum(weights) \n",
    "        final[j][i] = weights[0] * preds_df_fin_xgb.iloc[j:j+1, i].values[0] \\\n",
    "                            + weights[1] * preds_df_fin_lgbm.iloc[j:j+1, i].values[0] \\\n",
    "                            + weights[2] * preds_df_fin_lgbm.iloc[j:j+1, i].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final)\n",
    "final_values = pd.DataFrame((final_df.iloc[-1] - final_df.iloc[0]) / final_df.iloc[0])\n",
    "final_values_sharpe = -pd.DataFrame(((final_df.iloc[-1] - final_df.iloc[0]) / final_df.iloc[0]) / final_df.pct_change().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_values.index = dacon_sid_list\n",
    "final_values.columns = ['VALUE']\n",
    "final_values.reset_index(inplace = True)\n",
    "final_values.columns = ['종목코드', 'VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
